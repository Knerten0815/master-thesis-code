{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5e3ced0",
   "metadata": {},
   "source": [
    "## Similarity Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85819ea4-a2ce-4fdd-acd4-06437ce915f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C1CCCC(CC1)CCCCCNCCSS(=O)(=O)O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CC1=CC2=C(C3=C(CCC3)C(=O)O2)C(=C1)OC4C(C(C(C(O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C1=CC(=CC(=C1)Br)C(=O)NCC(=O)NN=CC2=C(C=C(C=C2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>COC(=O)CC(C1=CC=CC=C1)C2=C(C=C(C3=C2OC(=CC3=O)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CC1C(OC(CC1=C)(C(C(=O)NC2C3C(C(C(C(O3)CC(CO)OC...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              smiles\n",
       "0                     C1CCCC(CC1)CCCCCNCCSS(=O)(=O)O\n",
       "1  CC1=CC2=C(C3=C(CCC3)C(=O)O2)C(=C1)OC4C(C(C(C(O...\n",
       "2  C1=CC(=CC(=C1)Br)C(=O)NCC(=O)NN=CC2=C(C=C(C=C2...\n",
       "3  COC(=O)CC(C1=CC=CC=C1)C2=C(C=C(C3=C2OC(=CC3=O)...\n",
       "4  CC1C(OC(CC1=C)(C(C(=O)NC2C3C(C(C(C(O3)CC(CO)OC..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from rdkit.Chem import rdFingerprintGenerator\n",
    "\n",
    "filename = \"biostructures_combined\"\n",
    "path = os.path.join( \"data\", \"datasets\", filename + \".csv\")\n",
    "compounds = pd.read_csv(path)\n",
    "compounds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "895c5bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 730464 entries, 0 to 730463\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   smiles  730464 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 5.6+ MB\n"
     ]
    }
   ],
   "source": [
    "compounds.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c5c8236-3576-45e9-8824-d12295ba947c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code taken from https://github.com/florian-huber/molecular_fingerprint_comparisons\n",
    "\n",
    "import numba\n",
    "from numba import prange\n",
    "import numpy as np\n",
    "from fingerprint_computation import FingerprintGenerator, compute_fingerprints_from_smiles\n",
    "\n",
    "@numba.njit\n",
    "def ruzicka_similarity(A, B):\n",
    "    \"\"\"\n",
    "    Calculate the Ruzicka similarity between two count vectors.\n",
    "    \n",
    "    Parameters:\n",
    "    A (array-like): First count vector.\n",
    "    B (array-like): Second count vector.\n",
    "    \n",
    "    Returns:\n",
    "    float: Ruzicka similarity.\n",
    "    \"\"\"\n",
    "    \n",
    "    min_sum = np.sum(np.minimum(A, B))\n",
    "    max_sum = np.sum(np.maximum(A, B))\n",
    "    \n",
    "    return min_sum / max_sum\n",
    "\n",
    "\n",
    "@numba.jit(nopython=True, fastmath=True, parallel=True)\n",
    "def ruzicka_similarity_matrix(references: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Returns matrix of Ruzicka similarity between all-vs-all vectors of references and queries.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    references\n",
    "        Reference vectors as 2D numpy array. Expects that vector_i corresponds to\n",
    "        references[i, :].\n",
    "    queries\n",
    "        Query vectors as 2D numpy array. Expects that vector_i corresponds to\n",
    "        queries[i, :].\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    scores\n",
    "        Matrix of all-vs-all similarity scores. scores[i, j] will contain the score\n",
    "        between the vectors references[i, :] and queries[j, :].\n",
    "    \"\"\"\n",
    "\n",
    "    size = references.shape[0]\n",
    "    scores = np.zeros((size, size)) #, dtype=np.float32)\n",
    "    for i in prange(size):\n",
    "        for j in range(size):\n",
    "            scores[i, j] = ruzicka_similarity(references[i, :], references[j, :])\n",
    "    return scores\n",
    "\n",
    "\n",
    "def compute_similarity_matrix(compounds, sim_matrix_file, morgan_radius=9, fpSize=4096):\n",
    "    fpgen = rdFingerprintGenerator.GetMorganGenerator(radius=morgan_radius, fpSize=fpSize)\n",
    "    fingerprints_morgan_count = compute_fingerprints_from_smiles(compounds.smiles, fpgen, count=True, sparse=False, progress_bar=True)\n",
    "    similarities_morgan_count = ruzicka_similarity_matrix(fingerprints_morgan_count)\n",
    "    np.save(sim_matrix_file, similarities_morgan_count.astype(np.float32)) # big one ~5GB\n",
    "    return np.load(sim_matrix_file, mmap_mode ='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1514e2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "169.6197685546875"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "morgan_radius=9\n",
    "fpSize=2048\n",
    "parts = 16\n",
    "fingerprints_file = os.path.join(\"data\", \"group_similarity\", f\"{filename}_fingerprints_morgan{morgan_radius}_{fpSize}bits.npy\")\n",
    "fingerprints_morgan_count = np.load(fingerprints_file, mmap_mode ='r')\n",
    "(fingerprints_morgan_count.shape[0] /1500) * fingerprints_morgan_count.shape[0] * 128 * fingerprints_morgan_count.dtype.itemsize / 1024**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bade0e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/8 of the dataset will result in mols = 91308 mols.\n",
      "Disk size = 31.06 GB. With 5 GB per part, we will need 6 parts.\n",
      "Fingerprints ram size with 2048 = 0.70 GB\n"
     ]
    }
   ],
   "source": [
    "bits = 2048\n",
    "fraction = 8\n",
    "partsize = 5\n",
    "print(f\"1/{fraction} of the dataset will result in mols = {int(fingerprints_morgan_count.shape[0]/fraction)} mols.\")\n",
    "disk_size = (fingerprints_morgan_count.shape[0]/fraction) * (fingerprints_morgan_count.shape[0]/fraction) * fingerprints_morgan_count.dtype.itemsize / 1024**3\n",
    "fingerprints_disk_size = (fingerprints_morgan_count.shape[0]/fraction) * bits * fingerprints_morgan_count.dtype.itemsize / 1024**3\n",
    "print(f\"Disk size = {disk_size:.2f} GB. With {partsize} GB per part, we will need {int(disk_size/partsize)} parts.\")\n",
    "print(f\"Fingerprints ram size with {bits} = {fingerprints_disk_size:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6a4b021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.572998046875"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fingerprints_morgan_count.shape[0] * fingerprints_morgan_count.shape[1] * fingerprints_morgan_count.dtype.itemsize / 1024**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a15f39f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fingerprints_morgan_count.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f4ef7e-ee46-424d-9c4b-4b23eb22110a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sim Matrix Files not found.\n",
      "File data\\group_similarity\\biostructures_combined_fingerprints_morgan9_2048bits.npy found. Loading fingerprints.\n",
      "Fingerprints loaded. Running similarity matrix generation.\n",
      "Computing similarity matrix for part 0.\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n",
      "Computing similarity matrix for part 1.\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "morgan_radius=9\n",
    "fpSize=2048\n",
    "parts = 16\n",
    "\n",
    "fingerprints_file = os.path.join(\"data\", \"group_similarity\", f\"{filename}_fingerprints_morgan{morgan_radius}_{fpSize}bits.npy\")\n",
    "sim_matrix_files = []\n",
    "for part in range(parts):\n",
    "    sim_matrix_files.append(os.path.join(\"data\", \"group_similarity\", f\"{filename}_part{part}_ruzicka_similarities_morgan{morgan_radius}_{fpSize}bits.npy\"))\n",
    "try:\n",
    "    sim_matrices = [np.load(sim_matrix_file, mmap_mode='r') for sim_matrix_file in sim_matrix_files]\n",
    "    print(f\"Found {len(sim_matrices)} files. Loading similarity matrices.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Sim Matrix Files not found.\")\n",
    "    try:\n",
    "        fingerprints_morgan_count = np.load(fingerprints_file, mmap_mode ='r')\n",
    "        print(f\"File {fingerprints_file} found. Loading fingerprints.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File {fingerprints_file} not found. Running the fingerprint generation.\")\n",
    "        # fingerprint generation\n",
    "        fpgen = rdFingerprintGenerator.GetMorganGenerator(radius=morgan_radius, fpSize=fpSize)\n",
    "        fingerprints_morgan_count = compute_fingerprints_from_smiles(compounds.smiles, fpgen, count=True, sparse=False, progress_bar=True)\n",
    "        np.save(fingerprints_file, fingerprints_morgan_count.astype(np.float32))\n",
    "        fingerprints_morgan_count = np.load(fingerprints_file, mmap_mode ='r')\n",
    "    # sim matrix generation\n",
    "    print(\"Fingerprints loaded. Running similarity matrix generation.\")\n",
    "    for part in range(parts):\n",
    "        sim_matrix_file = sim_matrix_files[part]\n",
    "        if os.path.exists(sim_matrix_file):\n",
    "            print(f\"File {sim_matrix_file} already exists. Skipping.\")\n",
    "            continue\n",
    "        print(f\"Computing similarity matrix for part {part}.\")\n",
    "        start_idx = int(part * fingerprints_morgan_count.shape[0] / parts)\n",
    "        end_idx = int((part + 1) * fingerprints_morgan_count.shape[0] / parts)\n",
    "        %time\n",
    "        sim_matrix = ruzicka_similarity_matrix(fingerprints_morgan_count[start_idx:end_idx])\n",
    "        np.save(sim_matrix_file, sim_matrix.astype(np.float32))\n",
    "        sim_matrix = None\n",
    "    sim_matrices = [np.load(sim_matrix_file, mmap_mode='r') for sim_matrix_file in sim_matrix_files]\n",
    "\n",
    "print(sim_matrices[0].shape)\n",
    "sim_matrices[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d624b744",
   "metadata": {},
   "source": [
    "## Queries wih similiar groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1862ac3a",
   "metadata": {},
   "source": [
    "#### randomly select 30 analogues, if there are any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332cdd55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37811"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sim_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72e8f54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "memmap([[1.        , 0.14537445, 0.06024097, ..., 0.14432989, 0.09448819,\n",
       "         0.08896797],\n",
       "        [0.14537445, 1.        , 0.03361345, ..., 0.18604651, 0.07438017,\n",
       "         0.04727273],\n",
       "        [0.06024097, 0.03361345, 1.        , ..., 0.04      , 0.10460251,\n",
       "         0.13618676],\n",
       "        ...,\n",
       "        [0.05625   , 0.02731092, 0.11286682, ..., 0.025     , 0.06736842,\n",
       "         0.11924686],\n",
       "        [0.06586827, 0.0738255 , 0.01863354, ..., 0.07964602, 0.05952381,\n",
       "         0.02487562],\n",
       "        [0.03233831, 0.02319588, 0.06933333, ..., 0.01126761, 0.04010025,\n",
       "         0.07263923]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_matrix[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1442c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def select_analogue_groups(similarity_matrix, group_size=30, sim_range=(0.8, 0.9999), no_overlap=True, seed=42, print_mean_similarity=False):\n",
    "    \"\"\"\n",
    "    Selects groups of similar compounds based on a similarity matrix.\n",
    "    Each group contains a specified number of compounds that are similar to a given compound within a defined similarity range.\n",
    "    Parameters: \n",
    "        similarity_matrix (np.ndarray): A 2D numpy array where each row represents a compound and each column represents the similarity to other compounds.\n",
    "        group_size (int): The number of similar compounds to select for each compound.\n",
    "        sim_range (tuple): A tuple defining the lower and upper bounds of the similarity range to consider for selecting similar compounds.\n",
    "        no_overlap (bool): If True, ensures that selected compounds do not overlap with previously selected compounds.\n",
    "        seed (int): Random seed for reproducibility.\n",
    "        print_mean_similarity (bool): If True, prints the mean similarity of the selected compounds for each compound.\n",
    "        Returns:\n",
    "            analogue_dict (dict): A dictionary where keys are indices of the original compounds and values are lists of indices of selected similar compounds.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    analogue_dict = {}\n",
    "    used_indices =[]\n",
    "    for i in range(len(similarity_matrix)):\n",
    "        similar_indices = np.where((similarity_matrix[i] >= sim_range[0]) & (similarity_matrix[i] <= sim_range[1]))[0]\n",
    "        # remove already used ids from similar_indices\n",
    "        similar_indices = [idx for idx in similar_indices if idx not in used_indices]\n",
    "        # check if group size is large enough\n",
    "        if len(similar_indices) >= group_size:\n",
    "            if print_mean_similarity:\n",
    "                mean_similarity = np.mean(similarity_matrix[i][similar_indices])\n",
    "                print(f\"Index {i}: Found {len(similar_indices)} similar compounds with mean similarity {mean_similarity:.3f}. Picking {group_size} random matches.\")\n",
    "            \n",
    "            random_matches = random.sample(list(similar_indices), group_size)\n",
    "            #random_matches.sort()\n",
    "            analogue_dict[i] = random_matches\n",
    "            if no_overlap:\n",
    "                used_indices.append(i)\n",
    "                used_indices.extend(random_matches)\n",
    "    \n",
    "    return analogue_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a52e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{12: [36118,\n",
       "  4964,\n",
       "  1846,\n",
       "  15575,\n",
       "  13371,\n",
       "  31051,\n",
       "  6191,\n",
       "  21350,\n",
       "  3566,\n",
       "  16668,\n",
       "  26415,\n",
       "  33912,\n",
       "  25711,\n",
       "  9389,\n",
       "  35444],\n",
       " 809: [2119,\n",
       "  5949,\n",
       "  20237,\n",
       "  20602,\n",
       "  23223,\n",
       "  25548,\n",
       "  1578,\n",
       "  25294,\n",
       "  7248,\n",
       "  27739,\n",
       "  25745,\n",
       "  28949,\n",
       "  32941,\n",
       "  35992,\n",
       "  9181],\n",
       " 1578: [34429,\n",
       "  13876,\n",
       "  2274,\n",
       "  28197,\n",
       "  37231,\n",
       "  3216,\n",
       "  28047,\n",
       "  6317,\n",
       "  5671,\n",
       "  4893,\n",
       "  33154,\n",
       "  2936,\n",
       "  11227,\n",
       "  35699,\n",
       "  36397],\n",
       " 3113: [26266,\n",
       "  14563,\n",
       "  25409,\n",
       "  34396,\n",
       "  19814,\n",
       "  14897,\n",
       "  37106,\n",
       "  3193,\n",
       "  18801,\n",
       "  19710,\n",
       "  3971,\n",
       "  16334,\n",
       "  29081,\n",
       "  28459,\n",
       "  12810],\n",
       " 7630: [34874,\n",
       "  30652,\n",
       "  29799,\n",
       "  18830,\n",
       "  34437,\n",
       "  11144,\n",
       "  3761,\n",
       "  1790,\n",
       "  30883,\n",
       "  27423,\n",
       "  7320,\n",
       "  25558,\n",
       "  36876,\n",
       "  14336,\n",
       "  23933]}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogue_dict = select_analogue_groups(sim_matrix, group_size=30, sim_range=(0.8, 0.9999), no_overlap=True, seed=42)#, print_mean_similarity=True)\n",
    "print(len(analogue_dict))\n",
    "#analogue_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea1c48d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72477067"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_matrix[9][27959]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chemspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
